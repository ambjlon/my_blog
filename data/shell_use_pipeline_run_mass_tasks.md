## 问题
使用shell编写程序的时候, 我们可以通过循环和nohup结合启动大量的后台进程. 但是在操作系统上同时启动的进程数肯定有上限, 我们需要启动的进程数有时会超过这个上限. 比如, 通过hive客户端同时向hadoop提交大量的补数据的hql任务, 使用hive -e提交100个左右的任务机器就会卡死, 但是我们需要补数据的任务可能会有上千个.  
此时我们需要控制同时启动的进程数不超过最大上限, 使得这些任务一波一波的逐渐完成.

## 使用pipeline控制进程并发
shell下的管道可以用来进行进程间通信
