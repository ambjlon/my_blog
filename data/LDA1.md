　　LDA(Latent dirichlet allocation，潜在狄立克雷分配, )和其它主题模型（topic model）都属于概率建模（概率图模型，贝叶斯信念网络）这一更大领域。数据被看作是经过包括隐藏变量在内的生成过程得到的。生成过程定义了观测随机变量和隐藏随机变量的联合概率分布。通过使用联合分布来计算在给定观测变量下隐藏变量的条件分布（后验分布）来进行数据分析。LDA是在原来LSA (Latent Semantic Analysis)，pLSA（ProbabilisticLatent Semantic Analysis）的基础上进行改进得到的。  
******
## LDA建模时的直观想法  
　　我们把文档看成是由多个主题按不同的比例构成的，每个主题又在单词表上对应一个分布。如下图所示，《Seeking Life’s Bare(Genetic)Necessities》是一篇对基因数量进行数据分析的文章。  
![](http://media.xtwind.com/images/2015/06/21/6fee02df5b75a4ac469583dfe2393d27.jpg)  
　　文章中不同的词被高亮在不同的颜色。如“computer”和“prediction”之类有关数据分析的词以蓝色标记；如“life”和“organism”之类关于进化生物学的词以粉红色标记；如“sequenced”和“genes”之类有关遗传学的词以黄色标记。将所有词语进行这样的标记，并剔除“and”、“but”和“if”这类包含极少主题内容的词语后可以发现，这篇文章由不同主题以不同的比例组成，不同的topics由不同的单词按比例组成，右边的topics列表示了这种情况。更进一步地看，多个主题可以帮助人们在一堆科技论文中发现这篇文章。统计模型LDA就试图描述上述直观的现象。  
## LDA模型能做什么  
![](http://img.my.csdn.net/uploads/201304/07/1365306193_2030.jpg)  
　　主题建模的目的是为了自动地发现文档集中的主题。文档自然是可被观察到的，但主题结构——主题、主题直方图（或者分布）和主题的词分布——却是隐藏的。所以主题建模的中心问题就是利用看到的文档推断出隐藏的主题结构。这其实是给一个文档集合里面的文档在打标签。上图就是一个推断《Seeking Life’s Bare(Genetic)Necessities》（图一）的例子。使用主题建模算法（假设有100个主题）推断《科学》上17000篇文章的潜在主题结构，然后推断出最能描述图1中示例文章的主题分布（图左）。需要注意的是，尽管主题分布上有无穷个主题，但事实上只有其中的一小部分的概率不为零。进一步地，文章中词可被分主题进行组织，可以看到最常见的主题所包含的概率最大的词。  
![](http://media.xtwind.com/images/2015/06/21/a12515e748b1563f0c987e997626f7ff.jpg)  
　　需要强调的是，算法事先并不知道这些主题，文章也未有关键词或主题标记。计算潜在结构得到的主题分布可以产生所观察到的文档集合（由推断算法产生的主题对所分析的文档集合几乎都具有可解释性，主题似乎与语言的统计结构和LDA的具体概率假设有关）。如图3显示了《Yale Law Journal》中发现的主题（这里设置主题数为20）。主题由基因和数据分析替换为歧视和合同法。主题建模是管理、组织和标记大规模文本的一种算法。推断得到的隐藏结构近似于文档集的主题结构，能标记文档集中各个文档。这代替了痛苦的手工标记，并有助于信息检索，分类和语料库搜索。  


